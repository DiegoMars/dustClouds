{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import wget\n",
    "\n",
    "## File paths\n",
    "atlasFile = 'atlas.csv'\n",
    "listFile = 'listOfIds.txt'\n",
    "webFile = 'websites.txt'\n",
    "resultsFolder = 'results'\n",
    "library = 'library.txt'\n",
    "\n",
    "# initializers\n",
    "ra, dec, radius = 0, 0, 0.0014\n",
    "id = '0'\n",
    "stars = []\n",
    "allCSVs = []\n",
    "bands = [\"I4\"]#['I1', 'I2', 'I3', 'I4', 'M1', 'M2', 'M3']\n",
    "atlasFile = pd.read_csv(atlasFile)\n",
    "starter = 'https://irsa.ipac.caltech.edu/SIA?COLLECTION=spitzer_sha&RESPONSEFORMAT=CSV&POS=circle'\n",
    "\n",
    "# Convert Panda series to arrays\n",
    "objidA = pd.Series(atlasFile['objid']).array\n",
    "raA = pd.Series(atlasFile['ra']).array\n",
    "decA = pd.Series(atlasFile['dec']).array\n",
    "\n",
    "atlasFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes ids in listOfIds.txt into a list\n",
    "def listOut():\n",
    "    list = []\n",
    "    myfile = open(listFile, \"rt\")\n",
    "    contents = myfile.read() + '\\n'\n",
    "    myfile.close()\n",
    "    while len(contents) > 0:\n",
    "        index = contents.find('\\n')\n",
    "        id = contents[0:index]\n",
    "        list.append(id)\n",
    "        contents = contents[index+1:]\n",
    "    return(list)\n",
    "\n",
    "# Asks for Object ID, then returns ra and dec of the object is available\n",
    "# If not available, display error and ends program\n",
    "# Edit: replaces spaces in ID with underscores\n",
    "def search(id):\n",
    "    for i in range(len(objidA)):\n",
    "        if id == objidA[i]:\n",
    "            ra = raA[i]\n",
    "            dec = decA[i]\n",
    "            id = id.replace(' ', '_')\n",
    "            return (id, ra, dec)\n",
    "    print(f'Error: search()\\nInvalid id: {id}')\n",
    "    exit()\n",
    "\n",
    "# Rounds input to the 5th decimal and outputs string\n",
    "def roundCords(num):\n",
    "    temp = (num*100000)+0.5\n",
    "    temp = math.floor(temp)\n",
    "    temp = str(float(temp)/100000)\n",
    "    return(temp)\n",
    "\n",
    "# Outputs website\n",
    "def makeWeb(r, d, rad):\n",
    "    endP = f'{starter}+{r}+{d}+{rad}'\n",
    "    return(endP)\n",
    "\n",
    "# Makes the website and adds to a list\n",
    "def makeEntry(id):\n",
    "    id, ra, dec = search(id)\n",
    "    website = (makeWeb(roundCords(ra),roundCords(dec),roundCords(radius)))\n",
    "    check = False\n",
    "\n",
    "    #checks if the entry is already made\n",
    "    for i in stars:\n",
    "        if i[0] == id:\n",
    "            check = True\n",
    "\n",
    "    if check:\n",
    "        print(f'{id} entry already in listOfIds.txt file')\n",
    "    else:\n",
    "        print(f'{id} entry made!')\n",
    "        entry = [id, ra, dec, radius, website]\n",
    "        stars.append(entry)\n",
    "    return(stars)\n",
    "\n",
    "# Makes a number of random obj #s\n",
    "def randomIds(randomN):\n",
    "    for i in range(randomN):\n",
    "        websites = makeEntry(objidA[random.randrange(0, len(objidA))])\n",
    "    return(websites)\n",
    "\n",
    "# Takes a URL and returns the ending parts\n",
    "def breakUpUrl(string):\n",
    "    # Reverse the string to search from the end\n",
    "    reversed_string = string[::-1]\n",
    "    # Find the index of the first \"\\\" from the end\n",
    "    slash_index = reversed_string.find(\"/\")\n",
    "    # Get the substring after the \"\\\" and reverse it back\n",
    "    after_slash = reversed_string[:slash_index][::-1]\n",
    "    # Split the string by \"_\" and return the result\n",
    "    parts = after_slash.split(\"_\")\n",
    "    return parts\n",
    "\n",
    "# Splits url to look for the wanted bands and if it's a maic.fits, and marks which bands are included\n",
    "def checkBands(urls):\n",
    "    rowsToSave = []\n",
    "    includedBands = []\n",
    "    linkCounter = 0\n",
    "    for i in range(len(urls)):\n",
    "        parts = breakUpUrl(urls[i])\n",
    "        for band in bands:\n",
    "            if band == parts[1]:\n",
    "                if 'maic.fits' == parts[6]:\n",
    "                    rowsToSave.append(i)\n",
    "                    linkCounter += 1\n",
    "                    if band in includedBands:\n",
    "                        pass\n",
    "                    else:\n",
    "                        includedBands.append(band)\n",
    "    return(rowsToSave, includedBands, linkCounter)\n",
    "\n",
    "# Only grabs the urls that we are looking for\n",
    "def trimFat(entry):\n",
    "    filePath = f'{resultsFolder}/{entry[0]}.csv'\n",
    "    fat = pd.read_csv(filePath)\n",
    "    s_ras = pd.Series(fat['s_ra'])\n",
    "    s_decs = pd.Series(fat['s_dec'])\n",
    "    obs_ids = pd.Series(fat['obs_id']).array\n",
    "    urls = pd.Series(fat['access_url']).array\n",
    "    \n",
    "    #Searches for what rows to save\n",
    "    rowsToSave, includedBands, linkCounter = checkBands(urls)\n",
    "    entry.append(includedBands)\n",
    "    entry.append(linkCounter)\n",
    "    \n",
    "    # Overwrites a CSV file, keeping the 's_ra', 's_dec', 'obs_id', and 'access_url'\n",
    "    theMeat = []\n",
    "    for row in rowsToSave:\n",
    "        oneRow = []\n",
    "        oneRow.append(obs_ids[row])\n",
    "        oneRow.append(s_ras[row])\n",
    "        oneRow.append(s_decs[row])\n",
    "        oneRow.append(urls[row])\n",
    "        theMeat.append(oneRow)\n",
    "    theMeatDf = pd.DataFrame(theMeat, columns=['obs_id', 's_ra', 's_dec', 'access_url'])\n",
    "    theMeatDf.to_csv(filePath, mode='w')\n",
    "    return(entry)\n",
    "    \n",
    "# Download CSV from provided list from 'stars'\n",
    "def grabCSV(entry):\n",
    "    id = entry[0]\n",
    "    link = entry[4]\n",
    "\n",
    "    # adds all reference file names in 'results' in a list\n",
    "    rawResults = []\n",
    "    for file_path in os.listdir(f\"{resultsFolder}\"):\n",
    "        if os.path.isfile(os.path.join(resultsFolder, file_path)):\n",
    "            rawResults.append(file_path)\n",
    "    # adds all reference file names in 'results/references' in a list\n",
    "    rResults = []\n",
    "    for file_path in os.listdir(f\"{resultsFolder}/references\"):\n",
    "        if os.path.isfile(os.path.join(f\"{resultsFolder}/references\", file_path)):\n",
    "            if file_path != '.gitignore':\n",
    "                rResults.append(file_path)\n",
    "\n",
    "    #checks if the csv is already downloaded\n",
    "    if (id+'.csv') in rawResults:\n",
    "        print(f'{id}.csv already in results folder\\n')\n",
    "    elif (id+'.csv') in rResults:\n",
    "        print(f'{id}.csv already in results/references folder\\n')\n",
    "    else:\n",
    "        print('Grabbing...')\n",
    "        wget.download(link, f'{id}.csv')\n",
    "        os.rename(f'{id}.csv', f'{resultsFolder}/{id}.csv')\n",
    "        print(f'Downloaded: {id}.csv\\n')\n",
    "        entry = trimFat(entry)\n",
    "        return(entry)\n",
    "\n",
    "# Adds the ID, Ra, Dec, how many links, included bands, and reference csv link\n",
    "def updateLibrary():\n",
    "    wordsInFile = ''\n",
    "    print(stars)\n",
    "    for entry in stars:\n",
    "        print(entry)\n",
    "        wordsInFile = wordsInFile + f'ID: {entry[0]}\\nRA: {entry[1]} DEC: {entry[2]} RADIUS: {entry[3]}\\nNumber of Links: {entry[6]}\\nIncluded Bands: '\n",
    "        for i in range(len(entry[5])):\n",
    "            wordsInFile = wordsInFile + f'{entry[5][i]} '\n",
    "        wordsInFile = wordsInFile + f'\\n{entry[4]}\\n\\n'\n",
    "    f = open(library,'w')\n",
    "    f.write(wordsInFile)\n",
    "    f.close\n",
    "    print('Updated Library!\\n')\n",
    "\n",
    "# Self-explanatory tbh\n",
    "def downloadFITS(limit):\n",
    "    fitsFilesFolder = f'{resultsFolder}/fitsFiles'\n",
    "    # Lists out all CSVs\n",
    "    referenceCSVs = []\n",
    "    for file_path in os.listdir(resultsFolder):\n",
    "        if file_path[-3:] == \"csv\":\n",
    "            if os.path.isfile(os.path.join(resultsFolder, file_path)):\n",
    "                referenceCSVs.append(file_path)\n",
    "    # Lists out all FITS files in the results/fitsFiles folder\n",
    "    fitsFilesList = []\n",
    "    for file_path in os.listdir(fitsFilesFolder):\n",
    "        if file_path[-4:] == \"fits\":\n",
    "            if os.path.isfile(os.path.join(fitsFilesFolder, file_path)):\n",
    "                referenceCSVs.append(file_path)\n",
    "\n",
    "    # Starts downloading all CSVs \n",
    "    for csv in referenceCSVs:\n",
    "        # Downloads the FITS files until the limit\n",
    "        csvDF = pd.read_csv(f'{resultsFolder}/{csv}')\n",
    "        obsIDs = pd.Series(csvDF['obs_id']).array\n",
    "        urls = pd.Series(csvDF['access_url'])\n",
    "        counter = 0\n",
    "        print(f'Downloading from {csv}...\\n')\n",
    "        while counter < limit and counter < len(urls):\n",
    "            stringURL = str(urls[counter])\n",
    "            parts_string = stringURL.split(\"/\")\n",
    "\n",
    "            parts = breakUpUrl(urls[counter])\n",
    "            band = parts[1]\n",
    "            fileName = '_'.join([str(item) for item in parts])\n",
    "\n",
    "            if (fileName) in fitsFilesList:\n",
    "                print(f'{fileName} already in results/fitsFiles')\n",
    "            else:\n",
    "                wget.download(urls[counter], f'{resultsFolder}/fitsFiles/{fileName}') \n",
    "                #({band}){obsIDs[counter]}.fits')\n",
    "                print(f'\\tDownloaded ({fileName}\\n')\n",
    "                counter += 1\n",
    "\n",
    "        # Moves the CSV file into the results/references folder\n",
    "        os.rename(f'{resultsFolder}/{csv}', f'{resultsFolder}/references/{csv}')\n",
    "        print(f'Finished downloading from {csv}\\n')\n",
    "    print(f'Finished downloading FITs files\\n')\n",
    "\n",
    "\n",
    "# Self-explanatory again\n",
    "def askToDownload():\n",
    "    ask = input('Download FITS flies?(y/n): ')\n",
    "    if ask.lower() == 'y':\n",
    "        number = input('Limit of links per star: ')\n",
    "        if ask.isdigit:\n",
    "            downloadFITS(math.floor(int(number)))\n",
    "        else:\n",
    "            print('Invalid')\n",
    "    elif ask.lower != 'n':\n",
    "        print('Invalid')\n",
    "\n",
    "# Random links option\n",
    "def randomLinks():\n",
    "    number = input('How many stars: ')\n",
    "    if number.isdigit:\n",
    "        stars = randomIds(math.floor(int(number)))\n",
    "        for i in range(len(stars)):\n",
    "            stars[i] = grabCSV(stars[i])\n",
    "        print('Downloaded CSV(s)!')\n",
    "        updateLibrary()\n",
    "    else:\n",
    "        print('Invalid')\n",
    "\n",
    "# NonRandom links option\n",
    "def nonRandomLinks():\n",
    "    listOfIds = listOut()\n",
    "    for obj in range(len(listOfIds)):\n",
    "        stars = makeEntry(listOfIds[obj])\n",
    "    for i in range(len(stars)):\n",
    "        stars[i] = grabCSV(stars[i])\n",
    "    print('Downloaded CSV(s)!')\n",
    "    updateLibrary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = input('Look for links?(y/n): ')\n",
    "if start.lower() == 'y':\n",
    "    links = input('Random links?(y/n): ')\n",
    "    if links.lower() == 'y':\n",
    "        randomLinks()\n",
    "        askToDownload()\n",
    "    elif links.lower() == 'n':\n",
    "        nonRandomLinks()\n",
    "        askToDownload()\n",
    "    else:\n",
    "        print('Invalid')\n",
    "elif start.lower() == 'n':\n",
    "    askToDownload()\n",
    "else:\n",
    "    print('Invalid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
